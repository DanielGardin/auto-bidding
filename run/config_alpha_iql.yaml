general:
  project_path: /work/giovani.valdrighi/auto-bidding
  project_name: bidding_train_env
  experiment_name: iql_alpha_all
  device: cuda
  seed: 42

data:
  data_dir: data/traffic/new_rl_data/updated_rl_data.parquet
  buffer_size: 50_000
  val_periods: [25, 26, 27]

environment:
  environment: OfflineBiddingEnv
  environment_params: {}

model:
  actor: NormalStochasticMLP
  actor_params:
    activation: relu
    input_dim: 26
    hidden_dims: [256, 256]
    output_dim: 1

  budget: 750.0
  category: 0
  cpa: 8.0
  critic: QEmbedMLP
  critic_params:
    action_shape: [1]
    activation: relu
    embedding_dim: 64
    hidden_dims: [256, 256]
    observation_shape: [26]
  
  num_critics: 2
  strategy: AlphaBiddingStrategy
  value: MLP
  value_params:
    activation: relu
    hidden_dims: [256, 256]
    input_dim: 26

train:
  actor_optimizer: Adam
  actor_optimizer_params:
    lr: 0.0001
  batch_size: 256
  critic_optimizer: Adam
  critic_optimizer_params:
    lr: 0.0001
  expectile: 0.7
  gamma: 0.99
  num_epochs: 1000
  steps_per_epoch: 1_000
  tau: 0.005
  temperature: 3.0
  value_optimizer: Adam
  value_optimizer_params:
    lr: 0.0001

logging:
  log_dir: logs/iql
  checkpoint_interval: 1000
  use_wandb: false
  verbose: false